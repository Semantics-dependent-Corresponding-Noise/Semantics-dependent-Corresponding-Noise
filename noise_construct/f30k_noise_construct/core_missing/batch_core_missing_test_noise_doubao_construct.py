import base64
import os
import sys
import time
import signal
import json
import re
import asyncio
import aiofiles
from tqdm.asyncio import tqdm as async_tqdm
from openai import AsyncOpenAI
from asyncio import Lock, Semaphore
from concurrent.futures import ThreadPoolExecutor
from collections import Counter

# ==================== é…ç½®å‚æ•° ====================
# API é…ç½®
client = AsyncOpenAI(
    api_key="yours api",
    base_url="https://ark.cn-beijing.volces.com/api/v3/",
)

# æµ‹è¯•æ¨¡å¼é…ç½®
TEST_MODE = False  # è®¾ç½®ä¸ºTrueå¯ç”¨æµ‹è¯•æ¨¡å¼
if TEST_MODE:
    MAX_CONCURRENT_REQUESTS = 2  # æµ‹è¯•æ¨¡å¼å¹¶å‘æ•°
    SAVE_INTERVAL = 10  # æ¯10å¼ å›¾ç‰‡ä¿å­˜ä¸€ä¸ªæ–‡ä»¶
    MAX_TEST_IMAGES = 10  # åªæµ‹è¯•å‰10å¼ å›¾ç‰‡
else:
    MAX_CONCURRENT_REQUESTS = 20  # ç”Ÿäº§æ¨¡å¼å¹¶å‘æ•°
    SAVE_INTERVAL = 1000  # æ¯1000å¼ å›¾ç‰‡ä¿å­˜ä¸€ä¸ªæ–‡ä»¶
    MAX_TEST_IMAGES = None  # ä¸é™åˆ¶å›¾ç‰‡æ•°é‡

# è·¯å¾„é…ç½®
TEST_IDS_PATH = '/home/zbm/xjd/NPC-master/dataset/core_missing_Error_noise_f30k/annotations/scan_split/test_ids.txt'
IMAGE_NAMES_PATH = '/home/zbm/xjd/NPC-master/dataset/core_missing_Error_noise_f30k/annotations/scan_split/image_name.txt'
IMAGE_DIR = '/home/zbm/xjd/NPC-master/dataset/core_missing_Error_noise_f30k/images'
OUTPUT_DIR = '/home/zbm/xjd/NPC-master/f30k_noise_construct/core_missing/test_flickr'

# æ–‡ä»¶é…ç½®
LOG_FILE = os.path.join(OUTPUT_DIR, 'processing_flickr_test.log')
CHECKPOINT_FILE = os.path.join(OUTPUT_DIR, 'checkpoint_flickr_test.json')
PID_FILE = os.path.join(OUTPUT_DIR, 'processing_flickr_test.pid')

# å¤„ç†å‚æ•°
MAX_API_RETRIES = 3
MAX_REGENERATION_ATTEMPTS = 5
API_TIMEOUT = 120.0

# å…¨å±€çº¿ç¨‹æ± ç”¨äºæ–‡ä»¶I/O
io_executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix="FileIO")

# ==================== å¼‚æ­¥æ—¥å¿—ç³»ç»Ÿ ====================
class AsyncLogger:
    """å¼‚æ­¥åŒé‡è¾“å‡ºï¼šæ§åˆ¶å°+æ—¥å¿—æ–‡ä»¶"""
    def __init__(self, log_file):
        self.terminal = sys.stdout
        self.log_file = log_file
        self.lock = Lock()
        
    async def write(self, message):
        async with self.lock:
            self.terminal.write(message)
            self.terminal.flush()
            async with aiofiles.open(self.log_file, 'a', encoding='utf-8') as f:
                await f.write(message)
            
    def flush(self):
        self.terminal.flush()

    async def close(self):
        pass

# ==================== å…¨å±€é”å®šä¹‰ ====================
checkpoint_lock = None
failed_images_lock = None
logger = None

# ==================== ä¿¡å·å¤„ç† ====================
def signal_handler(signum, frame):
    print(f"\næ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨é€€å‡º...")
    sys.exit(0)

# ==================== æ•°æ®åŠ è½½ ====================
async def load_data():
    """åŠ è½½Flickr30kæµ‹è¯•é›†å›¾ç‰‡æ•°æ® - å»é‡å¤„ç†"""
    print(f"æ­£åœ¨åŠ è½½æµ‹è¯•é›†IDæ–‡ä»¶: {TEST_IDS_PATH}")
    print(f"æ­£åœ¨åŠ è½½å›¾ç‰‡åæ–‡ä»¶: {IMAGE_NAMES_PATH}")
    
    # è¯»å–test_idsæ–‡ä»¶ï¼ˆåŒ…å«é‡å¤IDï¼‰
    async with aiofiles.open(TEST_IDS_PATH, 'r', encoding='utf-8') as f:
        content = await f.read()
        lines = content.split('\n')
        test_indices = [int(line.strip()) for line in lines if line.strip().isdigit()]
    
    print(f"åŸå§‹æµ‹è¯•IDæ•°é‡ï¼ˆåŒ…å«é‡å¤ï¼‰: {len(test_indices)}")
    
    # è¯»å–image_namesæ–‡ä»¶
    async with aiofiles.open(IMAGE_NAMES_PATH, 'r', encoding='utf-8') as f:
        content = await f.read()
        all_image_names = [line.strip() for line in content.split('\n') if line.strip()]
    
    print(f"æ€»å›¾ç‰‡åæ•°é‡: {len(all_image_names)}")
    
    # âœ… å…³é”®ä¿®æ”¹ï¼šå»é‡å¤„ç†
    # æå–æ‰€æœ‰å”¯ä¸€ç´¢å¼•
    unique_indices = list(set(test_indices))
    unique_indices.sort()  # ä¿æŒé¡ºåº
    
    # ç»Ÿè®¡é‡å¤æƒ…å†µ
    id_counts = Counter(test_indices)
    total_repeats = len(test_indices) - len(unique_indices)
    
    print(f"âœ… å”¯ä¸€IDæ•°é‡ï¼ˆå»é‡åï¼‰: {len(unique_indices)}")
    print(f"ğŸ“Š é‡å¤ç»Ÿè®¡:")
    print(f"  é‡å¤IDæ€»æ•°: {total_repeats}")
    print(f"  å¹³å‡æ¯ä¸ªIDé‡å¤æ¬¡æ•°: {len(test_indices)/len(unique_indices):.2f}")
    
    # æ˜¾ç¤ºé‡å¤æœ€å¤šçš„å‡ ä¸ªID
    if total_repeats > 0:
        print(f"  é‡å¤æœ€å¤šçš„å‰5ä¸ªID:")
        for i, (id, count) in enumerate(id_counts.most_common(5), 1):
            print(f"    {i}. ID {id}: å‡ºç° {count} æ¬¡")
    
    # æ ¹æ®å”¯ä¸€ç´¢å¼•æå–å¯¹åº”çš„å›¾åƒæ–‡ä»¶å
    image_names_to_process = []
    for idx in unique_indices:
        if 0 <= idx < len(all_image_names):
            image_names_to_process.append(all_image_names[idx])
        else:
            print(f"âš  è­¦å‘Š: ç´¢å¼• {idx} è¶…å‡ºèŒƒå›´ (0-{len(all_image_names)-1})")
    
    print(f"ç”Ÿæˆ {len(image_names_to_process)} ä¸ªå”¯ä¸€å›¾ç‰‡å")
    
    # éªŒè¯å‰å‡ ä¸ªæ–‡ä»¶å
    if len(image_names_to_process) > 0:
        print(f"\nğŸ” å‰10ä¸ªå”¯ä¸€å›¾ç‰‡å:")
        for i in range(min(10, len(image_names_to_process))):
            print(f"  {i+1}. {image_names_to_process[i]}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        print(f"\nğŸ“ æ£€æŸ¥å‰5ä¸ªæ–‡ä»¶æ˜¯å¦å­˜åœ¨:")
        for i in range(min(5, len(image_names_to_process))):
            img_path = os.path.join(IMAGE_DIR, image_names_to_process[i])
            exists = os.path.exists(img_path)
            print(f"  {image_names_to_process[i]}: {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
    
    # æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰Nå¼ å›¾ç‰‡
    if TEST_MODE and MAX_TEST_IMAGES:
        if len(image_names_to_process) > MAX_TEST_IMAGES:
            print(f"\nğŸ”¬ æµ‹è¯•æ¨¡å¼: åªå¤„ç†å‰ {MAX_TEST_IMAGES} å¼ å›¾ç‰‡")
            image_names_to_process = image_names_to_process[:MAX_TEST_IMAGES]
    
    await logger.write(f"ğŸ“Š Flickr30kæ•°æ®ç»Ÿè®¡:\n")
    await logger.write(f"  åŸå§‹IDæ•°é‡ï¼ˆåŒ…å«é‡å¤ï¼‰: {len(test_indices)}\n")
    await logger.write(f"  å”¯ä¸€IDæ•°é‡ï¼ˆå»é‡åï¼‰: {len(unique_indices)}\n")
    await logger.write(f"  å¹³å‡é‡å¤æ¬¡æ•°: {len(test_indices)/len(unique_indices):.2f}\n")
    await logger.write(f"  ç”Ÿæˆ {len(image_names_to_process)} ä¸ªå”¯ä¸€æ–‡ä»¶å\n")
    
    return image_names_to_process

# ==================== æ£€æŸ¥ç‚¹ç³»ç»Ÿ ====================
async def load_checkpoint():
    """åŠ è½½æ£€æŸ¥ç‚¹"""
    if os.path.exists(CHECKPOINT_FILE):
        try:
            file_size = os.path.getsize(CHECKPOINT_FILE)
            if file_size == 0:
                await logger.write("æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤é…ç½®\n")
                return create_default_checkpoint()
            
            async with aiofiles.open(CHECKPOINT_FILE, 'r', encoding='utf-8') as f:
                content = await f.read()
            
            if not content.strip():
                await logger.write("æ£€æŸ¥ç‚¹æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤é…ç½®\n")
                return create_default_checkpoint()
                
            checkpoint = json.loads(content)
            await logger.write(f"æˆåŠŸåŠ è½½æ£€æŸ¥ç‚¹ï¼Œå·²å¤„ç† {checkpoint.get('processed_count', 0)} å¼ å›¾ç‰‡\n")
            return checkpoint
            
        except json.JSONDecodeError as e:
            await logger.write(f"æ£€æŸ¥ç‚¹æ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®\n")
            backup_file = f"{CHECKPOINT_FILE}.backup_{int(time.time())}"
            if os.path.exists(CHECKPOINT_FILE):
                os.rename(CHECKPOINT_FILE, backup_file)
            await logger.write(f"å·²å¤‡ä»½æŸåæ–‡ä»¶åˆ°: {backup_file}\n")
            return create_default_checkpoint()
        except Exception as e:
            await logger.write(f"åŠ è½½æ£€æŸ¥ç‚¹æ—¶å‡ºé”™: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®\n")
            return create_default_checkpoint()
    
    return create_default_checkpoint()

def create_default_checkpoint():
    """åˆ›å»ºé»˜è®¤æ£€æŸ¥ç‚¹"""
    return {
        "processed_count": 0,
        "file_count": 0,
        "failed_images": [],
        "all_descriptions": {},
        "current_file_number": 1,
        "current_file_start_idx": 0,
        "timestamp": time.time()
    }

def save_checkpoint_sync(checkpoint_data, checkpoint_path):
    """åŒæ­¥ä¿å­˜æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰"""
    try:
        temp_file = f"{checkpoint_path}.tmp"
        
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)
            f.flush()
            os.fsync(f.fileno())
        
        # åŸå­æ€§åœ°æ›¿æ¢æ–‡ä»¶
        os.replace(temp_file, checkpoint_path)
        return True
    except Exception as e:
        print(f"ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        if os.path.exists(temp_file):
            os.remove(temp_file)
        return False

async def save_checkpoint(checkpoint_data):
    """å¼‚æ­¥ä¿å­˜æ£€æŸ¥ç‚¹"""
    loop = asyncio.get_event_loop()
    success = await loop.run_in_executor(
        io_executor,
        save_checkpoint_sync,
        checkpoint_data,
        CHECKPOINT_FILE
    )
    return success

# ==================== å›¾åƒç¼–ç  ====================
def encode_image_to_base64(image_path):
    """åŒæ­¥ç¼–ç å›¾ç‰‡ä¸ºbase64"""
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        print(f"è¯»å–å›¾ç‰‡å¤±è´¥ {image_path}: {e}")
        return None

# ==================== æ ¸å¿ƒç”Ÿæˆé€»è¾‘ ====================
async def generate_single_description(image_path, img_name, temperature=0.8, retry_count=0, semaphore=None):
    """å•å¼ å›¾ç‰‡ç”Ÿæˆæè¿°ï¼Œä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘"""
    prompt1 = """You are a professional image description assistant. Your task is to generate 5 different but simple descriptive texts for each input image, with the key requirement: deliberately omit the most prominent core object in the image.Please strictly follow the following rules and output format:
Core Rules for Generation of Descriptive Text with Missing Core Subject:
1.Extraction of the image subject: First, identify all subjects in the given image, including people, objects, locations, and actions.
2.Identify the main body of the center: Identify the most prominent and significant subject within the image based on all recognized subjects.  
3.Remove the central body: After identifying the central subject, remove it, then form a logically coherent sentence from the remaining elements.
4.Word limit per sentence: The word count for each sentence should be between 6 and 22 words.
Example :
- Input Image: A guy stitching up another man's coat.
- Output Sentence: A man's coat.
- Input Image: A boys jumps into the water upside down.
- Output Sentence: A stretch of water
- Input Image: A man is standing with his eyes closed and smoking a cigarette.
- Output Sentence: A room.
Strict Output Format:
Only output the modified sentence directly. Do NOT add any extra content (such as explanations, notes, or greetings)."""
    
    if retry_count > 0:
        prompt1 += f"\n\nIMPORTANT: You previously generated {retry_count} descriptions, but we need exactly 5 unique descriptions. Please generate {5 - retry_count} more unique descriptions that are different from the previous ones."
    
    base64_image = encode_image_to_base64(image_path)
    if not base64_image:
        return ""
    
    user_content = [
        {"type": "text", "text": f"Image {img_name}:"},
        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
    ]
    
    async with semaphore:
        for attempt in range(MAX_API_RETRIES):
            try:
                completion = await asyncio.wait_for(
                    client.chat.completions.create(
                        model="doubao-seed-1-6-vision-250815",
                        messages=[
                            {"role": "system", "content": prompt1},
                            {"role": "user", "content": user_content}
                        ],
                        temperature=temperature,
                        max_tokens=500,
                    ),
                    timeout=API_TIMEOUT
                )
                return completion.choices[0].message.content.strip()
            except Exception as e:
                if attempt == MAX_API_RETRIES - 1:
                    await logger.write(f"âŒ {img_name}: APIè°ƒç”¨å¤±è´¥: {str(e)[:50]}\n")
                    return ""
                await asyncio.sleep(2)
    
    return ""

def parse_single_response(response_text):
    """è§£æå•å¼ å›¾ç‰‡çš„æè¿° - åªæå–çº¯æè¿°æ–‡æœ¬"""
    if not response_text:
        return []
    
    lines = [line.strip() for line in response_text.split('\n') if line.strip()]
    filtered_lines = []
    
    for line in lines:
        # ç§»é™¤å›¾ç‰‡æ–‡ä»¶å
        if any(ext in line for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']):
            continue
        # ç§»é™¤æ•°å­—ç¼–å·
        elif re.match(r'^\d+\.\s*', line):
            line = re.sub(r'^\d+\.\s*', '', line)
            filtered_lines.append(line)
        # ç§»é™¤å…¶ä»–å¯èƒ½çš„å‰ç¼€
        elif re.match(r'^[â€¢\-*]\s*', line):
            line = re.sub(r'^[â€¢\-*]\s*', '', line)
            filtered_lines.append(line)
        # ç§»é™¤åŒ…å«"Image:"ç­‰å‰ç¼€çš„è¡Œ
        elif re.match(r'^(Image|å›¾ç‰‡|IMG|img)\s*[:ï¼š]', line, re.IGNORECASE):
            continue
        else:
            filtered_lines.append(line)
    
    # æ¸…æ´—æè¿°æ–‡æœ¬
    cleaned_lines = []
    for line in filtered_lines:
        # ç§»é™¤å¯èƒ½åŒ…å«çš„å›¾ç‰‡æ–‡ä»¶å
        line = re.sub(r'\b\d+\.jpg\b', '', line, flags=re.IGNORECASE)
        line = re.sub(r'\bimage\s*\d+\b', '', line, flags=re.IGNORECASE)
        line = line.strip()
        
        # ç§»é™¤å¼€å¤´ç»“å°¾çš„æ ‡ç‚¹
        line = re.sub(r'^[":\-\s]+', '', line)
        line = re.sub(r'[":\-\s]+$', '', line)
        
        if line:
            cleaned_lines.append(line)
    
    return cleaned_lines

async def process_single_image_with_retry(img_name, img_path, semaphore):
    """å¤„ç†å•å¼ å›¾ç‰‡ï¼Œå¦‚æœä¸è¶³5æ¡æè¿°åˆ™é‡æ–°ç”Ÿæˆ"""
    all_descriptions = []
    seen_descriptions = set()
    temperature = 0.8
    regeneration_attempts = 0
    
    while len(all_descriptions) < 5 and regeneration_attempts < MAX_REGENERATION_ATTEMPTS:
        needed = 5 - len(all_descriptions)
        
        if regeneration_attempts > 0:
            await logger.write(f"  â†³ {img_name}: ç¬¬{regeneration_attempts+1}æ¬¡é‡è¯•ï¼Œè¿˜éœ€è¦{needed}æ¡æè¿°\n")
            temperature = min(1.2, temperature + 0.1)
        
        response_text = await generate_single_description(img_path, img_name, temperature, len(all_descriptions), semaphore)
        new_descriptions = parse_single_response(response_text)
        
        if not new_descriptions:
            await logger.write(f"  â†³ {img_name}: ç¬¬{regeneration_attempts+1}æ¬¡è°ƒç”¨è¿”å›ç©ºç»“æœ\n")
            regeneration_attempts += 1
            await asyncio.sleep(2)
            continue
        
        unique_new_descriptions = []
        for desc in new_descriptions:
            cleaned_desc = desc.strip()
            # ç§»é™¤è¿‡çŸ­çš„æè¿°
            if len(cleaned_desc.split()) < 3:
                continue
            # æ£€æŸ¥æ˜¯å¦é‡å¤
            if cleaned_desc not in seen_descriptions and cleaned_desc not in all_descriptions:
                unique_new_descriptions.append(cleaned_desc)
                seen_descriptions.add(cleaned_desc)
        
        if unique_new_descriptions:
            all_descriptions.extend(unique_new_descriptions[:needed])
        
        regeneration_attempts += 1
        
        if len(all_descriptions) < 5:
            await asyncio.sleep(1)
    
    if len(all_descriptions) >= 5:
        result = all_descriptions[:5]
        await logger.write(f"âœ“ {img_name}: æˆåŠŸç”Ÿæˆ5æ¡æè¿°ï¼ˆå°è¯•{regeneration_attempts}æ¬¡ï¼‰\n")
        return result, False
    
    await logger.write(f"âŒ {img_name}: æ— æ³•ç”Ÿæˆ5æ¡æè¿°ï¼Œåªæœ‰{len(all_descriptions)}æ¡\n")
    return [f"æè¿°ç”Ÿæˆå¤±è´¥_{i+1}" for i in range(5)], True

async def process_single_image(img_name, img_path, semaphore):
    """å¤„ç†å•å¼ å›¾ç‰‡çš„ä¸»å‡½æ•°"""
    try:
        return await process_single_image_with_retry(img_name, img_path, semaphore)
    except Exception as e:
        await logger.write(f"âŒ {img_name}: å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)[:50]}\n")
        return [f"å¤„ç†å¼‚å¸¸_{i+1}" for i in range(5)], True

# ==================== æ‰¹é‡ä¿å­˜åŠŸèƒ½ ====================
async def save_images_file(file_number, all_descriptions, image_names_to_process, start_idx, end_idx):
    """ä¿å­˜æ¯æ‰¹å›¾ç‰‡çš„æè¿°åˆ°ä¸€ä¸ªæ–‡ä»¶ - åªä¿å­˜çº¯æè¿°æ–‡æœ¬"""
    output_file_path = os.path.join(OUTPUT_DIR, f'test_caps_5_per_image_part{file_number:03d}.txt')
    
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜ç¬¬ {file_number} ä¸ªæ–‡ä»¶: {output_file_path}")
    print(f"  å›¾ç‰‡ç´¢å¼•èŒƒå›´: {start_idx} åˆ° {end_idx-1}")
    print(f"  åº”åŒ…å«å›¾ç‰‡æ•°: {end_idx - start_idx}")
    
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_file_path), exist_ok=True)
        
        lines_to_write = []
        saved_count = 0
        missing_count = 0
        failed_count = 0
        
        print(f"  æ­£åœ¨ä¿å­˜å›¾ç‰‡æè¿°ï¼ˆçº¯æ–‡æœ¬ï¼‰:")
        
        for i in range(start_idx, end_idx):
            img_name = image_names_to_process[i]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æè¿°
            if img_name not in all_descriptions:
                descriptions = [f"æè¿°æœªç”Ÿæˆ_{j+1}" for j in range(5)]
                missing_count += 1
            else:
                descriptions = all_descriptions[img_name]
                
                if not descriptions:
                    descriptions = [f"æè¿°ä¸ºç©º_{j+1}" for j in range(5)]
                    missing_count += 1
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¤±è´¥æè¿°
            is_failed = any("å¤±è´¥" in desc or "æœªç”Ÿæˆ" in desc or "ä¸ºç©º" in desc or "å¼‚å¸¸" in desc for desc in descriptions)
            if is_failed:
                failed_count += 1
            
            # ç¡®ä¿æœ‰5ä¸ªæè¿°
            if len(descriptions) < 5:
                missing = 5 - len(descriptions)
                placeholders = [f"è¡¥å……æè¿°_{j+1}" for j in range(missing)]
                descriptions = descriptions + placeholders
                missing_count += 1
            elif len(descriptions) > 5:
                descriptions = descriptions[:5]
            
            # æ·»åŠ çº¯æè¿°æ–‡æœ¬
            for desc in descriptions:
                clean_desc = desc.strip()
                # æ¸…ç†å¯èƒ½çš„å›¾ç‰‡åæ®‹ç•™
                clean_desc = re.sub(r'\b\d+\.jpg\b', '', clean_desc, flags=re.IGNORECASE)
                clean_desc = re.sub(r'\bimage\s*\d+\b', '', clean_desc, flags=re.IGNORECASE)
                clean_desc = clean_desc.strip()
                
                if not clean_desc:
                    clean_desc = "æè¿°å†…å®¹ä¸ºç©º"
                
                lines_to_write.append(clean_desc)
            
            saved_count += 1
            
            if (i - start_idx + 1) % 10 == 0:
                print(f"    å·²å¤„ç† {i-start_idx+1}/{end_idx-start_idx} å¼ å›¾ç‰‡")
        
        print(f"\n  å‡†å¤‡å†™å…¥ {len(lines_to_write)} è¡Œçº¯æè¿°æ–‡æœ¬")
        print(f"  æŒ‰é¡ºåºå¤„ç†äº† {saved_count} å¼ å›¾ç‰‡")
        if missing_count > 0:
            print(f"  âš  æœ‰ {missing_count} å¼ å›¾ç‰‡æ²¡æœ‰å®Œæ•´æè¿°æ•°æ®")
        if failed_count > 0:
            print(f"  âŒ æœ‰ {failed_count} å¼ å›¾ç‰‡ç”Ÿæˆå¤±è´¥")
        
        # å†™å…¥æ–‡ä»¶
        with open(output_file_path, 'w', encoding='utf-8') as f:
            for line in lines_to_write:
                f.write(line + "\n")
            f.flush()
            os.fsync(f.fileno())
        
        # éªŒè¯æ–‡ä»¶
        if os.path.exists(output_file_path):
            file_size = os.path.getsize(output_file_path)
            print(f"\n  âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ!")
            print(f"    å¤§å°: {file_size} å­—èŠ‚")
            print(f"    å›¾ç‰‡: {saved_count} å¼ ")
            print(f"    æè¿°è¡Œæ•°: {len(lines_to_write)} è¡Œ")
            
            # éªŒè¯æ–‡ä»¶å†…å®¹
            with open(output_file_path, 'r', encoding='utf-8') as f:
                first_few_lines = [f.readline().strip() for _ in range(5)]
                print(f"\n    æ–‡ä»¶å‰5è¡Œå†…å®¹:")
                for idx, line in enumerate(first_few_lines, 1):
                    print(f"      è¡Œ{idx}: {line[:60]}...")
            
            await logger.write(f"\nâœ… å·²ä¿å­˜ç¬¬ {file_number} ä¸ªæ–‡ä»¶: {output_file_path}\n")
            await logger.write(f"   åŒ…å«å›¾ç‰‡ç´¢å¼• {start_idx} åˆ° {end_idx-1} (å…±{saved_count}å¼ å›¾ç‰‡)\n")
            await logger.write(f"   æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚, {len(lines_to_write)} è¡Œæè¿°\n")
            if missing_count > 0:
                await logger.write(f"   âš  {missing_count}å¼ å›¾ç‰‡æ²¡æœ‰å®Œæ•´æè¿°æ•°æ®\n")
            
            return saved_count, failed_count
        else:
            print(f"  âŒ æ–‡ä»¶æœªåˆ›å»º!")
            return 0, 0
            
    except Exception as e:
        print(f"  âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 0, 0

# ==================== è¿›åº¦è·Ÿè¸ªå™¨ ====================
class ProgressTracker:
    """è·Ÿè¸ªå¤„ç†è¿›åº¦"""
    def __init__(self, total_images):
        self.total = total_images
        self.processed = 0
        self.lock = Lock()
        self.start_time = time.time()
        self.last_log_time = time.time()
        self.last_progress_log = 0
    
    async def update(self, count=1):
        async with self.lock:
            self.processed += count
            
            if self.processed > self.total:
                self.processed = self.total
            
            progress = self.processed / self.total * 100 if self.total > 0 else 0
            elapsed = time.time() - self.start_time
            
            current_time = time.time()
            if self.processed - self.last_progress_log >= 10 or current_time - self.last_log_time > 5:
                if elapsed > 0:
                    speed = self.processed / elapsed
                    eta = (self.total - self.processed) / speed if speed > 0 and self.processed < self.total else 0
                    
                    await logger.write(
                        f"ğŸ“Š è¿›åº¦: {self.processed}/{self.total} ({progress:.1f}%) | "
                        f"é€Ÿåº¦: {speed:.2f} å¼ /ç§’ | ETA: {eta/60:.1f} åˆ†é’Ÿ\n"
                    )
                self.last_log_time = current_time
                self.last_progress_log = self.processed

# ==================== å¤„ç†å•ä¸ªæ–‡ä»¶çš„å›¾ç‰‡ ====================
async def process_single_file_images(file_number, start_idx, end_idx, image_names_to_process, 
                                    all_descriptions, failed_images, semaphore, progress_tracker):
    """å¤„ç†å•ä¸ªæ–‡ä»¶çš„æ‰€æœ‰å›¾ç‰‡"""
    print(f"\nğŸ“ å¼€å§‹å¤„ç†ç¬¬ {file_number} ä¸ªæ–‡ä»¶")
    print(f"  å›¾ç‰‡ç´¢å¼•: {start_idx} åˆ° {end_idx-1}")
    print(f"  å…± {end_idx - start_idx} å¼ å›¾ç‰‡")
    
    file_successful_count = 0
    file_failed_count = 0
    
    # åˆ›å»ºå¹¶å‘ä»»åŠ¡
    tasks = []
    for idx in range(start_idx, end_idx):
        img_name = image_names_to_process[idx]
        img_path = os.path.join(IMAGE_DIR, img_name)
        
        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
        if not os.path.exists(img_path):
            await logger.write(f"âŒ {img_name}: æ–‡ä»¶ä¸å­˜åœ¨\n")
            async with failed_images_lock:
                all_descriptions[img_name] = [f"æ–‡ä»¶ç¼ºå¤±_{j+1}" for j in range(5)]
                failed_images.append(img_name)
                file_failed_count += 1
            await progress_tracker.update(1)
            continue
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
        if img_name in all_descriptions and all_descriptions[img_name]:
            await logger.write(f"â© {img_name}: å·²å¤„ç†ï¼Œè·³è¿‡\n")
            await progress_tracker.update(1)
            continue
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        task = asyncio.create_task(process_single_image(img_name, img_path, semaphore))
        tasks.append((task, idx, img_name))
    
    if not tasks:
        print(f"  â© å½“å‰æ–‡ä»¶æ²¡æœ‰éœ€è¦å¤„ç†çš„ä»»åŠ¡")
        return file_successful_count, file_failed_count
    
    print(f"  ğŸš€ å¼€å§‹å¹¶å‘å¤„ç† {len(tasks)} ä¸ªä»»åŠ¡ (å¹¶å‘æ•°: {MAX_CONCURRENT_REQUESTS})...")
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await asyncio.gather(*[t[0] for t in tasks], return_exceptions=True)
    
    # å¤„ç†ç»“æœ
    for (task, idx, img_name), result in zip(tasks, results):
        if isinstance(result, Exception):
            await logger.write(f"âŒ {img_name}: ä»»åŠ¡æ‰§è¡Œå¤±è´¥ {str(result)[:50]}\n")
            async with checkpoint_lock:
                all_descriptions[img_name] = [f"ä»»åŠ¡å¤±è´¥_{i+1}" for i in range(5)]
            async with failed_images_lock:
                failed_images.append(img_name)
            file_failed_count += 1
            await progress_tracker.update(1)
        elif isinstance(result, tuple) and len(result) == 2:
            descriptions, is_failed = result
            async with checkpoint_lock:
                all_descriptions[img_name] = descriptions
            if is_failed:
                async with failed_images_lock:
                    failed_images.append(img_name)
                file_failed_count += 1
            else:
                file_successful_count += 1
            await progress_tracker.update(1)
        else:
            await logger.write(f"âš  {img_name}: è¿”å›ç»“æœæ ¼å¼å¼‚å¸¸\n")
            async with checkpoint_lock:
                all_descriptions[img_name] = [f"æ ¼å¼é”™è¯¯_{i+1}" for i in range(5)]
            async with failed_images_lock:
                failed_images.append(img_name)
            file_failed_count += 1
            await progress_tracker.update(1)
    
    return file_successful_count, file_failed_count

# ==================== ä¸»ç¨‹åº ====================
async def main_async():
    """ä¸»å¼‚æ­¥å‡½æ•°"""
    global logger, checkpoint_lock, failed_images_lock
    
    # åˆå§‹åŒ–å…¨å±€é”
    checkpoint_lock = Lock()
    failed_images_lock = Lock()
    
    logger = AsyncLogger(LOG_FILE)
    sys.stdout = sys.stderr = logger.terminal
    
    try:
        print("=" * 60)
        print("ğŸš€ Flickr30kæµ‹è¯•é›†å›¾ç‰‡æè¿°ç”Ÿæˆç¨‹åºå¯åŠ¨ï¼ˆå»é‡æ¨¡å¼ï¼‰")
        if TEST_MODE:
            print("ğŸ”¬ æµ‹è¯•æ¨¡å¼: 2å¹¶å‘ï¼Œæ¯10å¼ å›¾ç‰‡ä¿å­˜ä¸€ä¸ªæ–‡ä»¶")
        print(f"è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
        print(f"å¹¶å‘æ•°: {MAX_CONCURRENT_REQUESTS}")
        print(f"ä¿å­˜é—´éš”: æ¯{SAVE_INTERVAL}å¼ å›¾ç‰‡ä¿å­˜ä¸€ä¸ªæ–‡ä»¶")
        print("=" * 60)
        
        # åŠ è½½æ•°æ®ï¼ˆå»é‡å¤„ç†ï¼‰
        print("\nğŸ“‹ æ­£åœ¨åŠ è½½Flickr30kæµ‹è¯•é›†æ•°æ®ï¼ˆå»é‡å¤„ç†ï¼‰...")
        image_names_to_process = await load_data()
        total_images = len(image_names_to_process)
        
        if total_images == 0:
            print("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°è¦å¤„ç†çš„å›¾ç‰‡!")
            return
        
        print(f"\nâœ… æ€»å…±éœ€è¦å¤„ç† {total_images} å¼ å”¯ä¸€å›¾ç‰‡")
        print(f"   é¢„æœŸç»“æœ: {total_images} å¼ å›¾ç‰‡ Ã— 5æ¡æè¿° = {total_images * 5} è¡Œæè¿°")
        
        total_files = (total_images + SAVE_INTERVAL - 1) // SAVE_INTERVAL
        print(f"   å°†ä¿å­˜ {total_files} ä¸ªæ–‡ä»¶")
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        print("\nğŸ” æ­£åœ¨åŠ è½½æ£€æŸ¥ç‚¹...")
        checkpoint = await load_checkpoint()
        processed_count = checkpoint.get("processed_count", 0)
        file_count = checkpoint.get("file_count", 0)
        failed_images = checkpoint.get("failed_images", [])
        all_descriptions = checkpoint.get("all_descriptions", {})
        current_file_number = checkpoint.get("current_file_number", 1)
        current_file_start_idx = checkpoint.get("current_file_start_idx", 0)
        
        # åˆå§‹åŒ–æè¿°å­—å…¸
        for img_name in image_names_to_process:
            if img_name not in all_descriptions:
                all_descriptions[img_name] = []
        
        print(f"ğŸ“Š æ£€æŸ¥ç‚¹æ¢å¤:")
        print(f"  å·²å¤„ç†å›¾ç‰‡: {processed_count}/{total_images}")
        print(f"  å·²ä¿å­˜æ–‡ä»¶: {file_count}/{total_files}")
        print(f"  å½“å‰å¤„ç†æ–‡ä»¶: ç¬¬{current_file_number}ä¸ª")
        print(f"  å¤±è´¥å›¾ç‰‡æ•°: {len(failed_images)}")
        print(f"  å¹¶å‘æ•°: {MAX_CONCURRENT_REQUESTS}")
        
        await logger.write(f"ğŸ” æ£€æŸ¥ç‚¹æ¢å¤: {processed_count}/{total_images} å¼ å›¾ç‰‡å·²å¤„ç†\n")
        await logger.write(f"âŒ å¤±è´¥å›¾ç‰‡æ•°: {len(failed_images)}\n")
        await logger.write(f"{'='*60}\n")
        
        start_time = time.time()
        
        # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘
        semaphore = Semaphore(MAX_CONCURRENT_REQUESTS)
        progress_tracker = ProgressTracker(total_images)
        
        # è®¾ç½®è¿›åº¦ä»å·²å¤„ç†æ•°é‡å¼€å§‹
        progress_tracker.processed = processed_count
        
        # æŒ‰æ–‡ä»¶é¡ºåºå¤„ç†
        total_successful = 0
        total_failed = 0
        
        for file_number in range(current_file_number, total_files + 1):
            start_idx = (file_number - 1) * SAVE_INTERVAL
            end_idx = min(start_idx + SAVE_INTERVAL, total_images)
            
            print(f"\n{'='*60}")
            print(f"ğŸ“ å¤„ç†ç¬¬ {file_number}/{total_files} ä¸ªæ–‡ä»¶")
            print(f"  å›¾ç‰‡ç´¢å¼•: {start_idx} åˆ° {end_idx-1}")
            print(f"  å…± {end_idx - start_idx} å¼ å›¾ç‰‡")
            print(f"{'='*60}")
            
            await logger.write(f"\nğŸ“ å¼€å§‹å¤„ç†ç¬¬ {file_number} ä¸ªæ–‡ä»¶ (å›¾ç‰‡ {start_idx}-{end_idx-1})\n")
            
            # å¤„ç†å½“å‰æ–‡ä»¶çš„æ‰€æœ‰å›¾ç‰‡
            file_successful, file_failed = await process_single_file_images(
                file_number, start_idx, end_idx, image_names_to_process,
                all_descriptions, failed_images, semaphore, progress_tracker
            )
            
            total_successful += file_successful
            total_failed += file_failed
            
            print(f"\nğŸ“Š ç¬¬ {file_number} ä¸ªæ–‡ä»¶å¤„ç†å®Œæˆ:")
            print(f"  æˆåŠŸ: {file_successful} å¼ ")
            print(f"  å¤±è´¥: {file_failed} å¼ ")
            
            # ç«‹å³ä¿å­˜å½“å‰æ–‡ä»¶
            print(f"\nğŸ’¾ ç«‹å³ä¿å­˜ç¬¬ {file_number} ä¸ªæ–‡ä»¶ï¼ˆçº¯æè¿°æ–‡æœ¬ï¼‰...")
            saved_count, failed_in_file = await save_images_file(
                file_number, all_descriptions, image_names_to_process, start_idx, end_idx
            )
            
            if saved_count > 0:
                print(f"  âœ… ç¬¬ {file_number} ä¸ªæ–‡ä»¶ä¿å­˜æˆåŠŸ!")
                print(f"     åŒ…å« {saved_count} å¼ å›¾ç‰‡çš„æè¿°")
                
                # æ›´æ–°æ£€æŸ¥ç‚¹
                checkpoint_data = {
                    "processed_count": end_idx,
                    "file_count": file_number,
                    "failed_images": failed_images,
                    "all_descriptions": all_descriptions,
                    "current_file_number": file_number + 1,
                    "current_file_start_idx": end_idx,
                    "timestamp": time.time()
                }
                
                async with checkpoint_lock:
                    await save_checkpoint(checkpoint_data)
                
                print(f"  ğŸ’¾ æ£€æŸ¥ç‚¹å·²æ›´æ–°: æ–‡ä»¶{file_number}, å›¾ç‰‡{end_idx}")
            else:
                print(f"  âŒ ç¬¬ {file_number} ä¸ªæ–‡ä»¶ä¿å­˜å¤±è´¥!")
            
            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            current_time = time.time()
            elapsed = current_time - start_time
            if elapsed > 0:
                current_processed = min(file_number * SAVE_INTERVAL, total_images)
                speed = current_processed / elapsed
                remaining_images = total_images - current_processed
                eta = remaining_images / speed if speed > 0 else 0
                
                print(f"\nğŸ“ˆ æ€»ä½“è¿›åº¦:")
                print(f"  å·²å¤„ç†æ–‡ä»¶: {file_number}/{total_files}")
                print(f"  å·²å¤„ç†å›¾ç‰‡: {current_processed}/{total_images}")
                print(f"  å¹³å‡é€Ÿåº¦: {speed:.2f} å¼ /ç§’")
                if remaining_images > 0:
                    print(f"  é¢„è®¡å‰©ä½™æ—¶é—´: {eta/60:.1f} åˆ†é’Ÿ")
            
            # æ¯ä¸ªæ–‡ä»¶å¤„ç†åç­‰å¾…ä¸€ä¸‹
            if file_number < total_files:
                print(f"\nâ³ å‡†å¤‡å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶ï¼Œç­‰å¾…3ç§’...")
                await asyncio.sleep(3)
        
        # æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ
        print(f"\n{'='*60}")
        print("ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ!")
        
        # ä¿å­˜å¤±è´¥å›¾ç‰‡åˆ—è¡¨
        if failed_images:
            failed_file = os.path.join(OUTPUT_DIR, 'failed_test_images.txt')
            print(f"\nğŸ“‹ ä¿å­˜å¤±è´¥å›¾ç‰‡åˆ—è¡¨åˆ°: {failed_file}")
            
            try:
                with open(failed_file, 'w', encoding='utf-8') as f:
                    for img_name in failed_images:
                        f.write(f"{img_name}\n")
                print(f"å¤±è´¥å›¾ç‰‡åˆ—è¡¨å·²ä¿å­˜ ({len(failed_images)}å¼ )")
            except Exception as e:
                print(f"ä¿å­˜å¤±è´¥å›¾ç‰‡åˆ—è¡¨æ—¶å‡ºé”™: {e}")
        
        total_time = time.time() - start_time
        
        print(f"\n{'='*60}")
        print("âœ… å¤„ç†å®Œæˆ!")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’ ({total_time/60:.2f} åˆ†é’Ÿ)")
        print(f"ğŸš€ å¹³å‡é€Ÿåº¦: {total_images/total_time:.2f} å¼ /ç§’")
        print(f"ğŸ“Š æˆåŠŸ: {total_successful} å¼  | å¤±è´¥: {total_failed} å¼ ")
        print(f"ğŸ“ ä¿å­˜æ–‡ä»¶æ•°: {total_files} ä¸ª")
        print(f"ğŸ“ æ€»æè¿°è¡Œæ•°: {total_images * 5} è¡Œ")
        print(f"{'='*60}")
        
        # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
        print("\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨:")
        import glob
        files = glob.glob(os.path.join(OUTPUT_DIR, "test_caps_5_per_image_part*.txt"))
        for file in sorted(files):
            size = os.path.getsize(file)
            with open(file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            print(f"  {os.path.basename(file)} - {size} å­—èŠ‚, {len(lines)} è¡Œ, {len(lines)//5} å¼ å›¾ç‰‡")
            
            if file == files[0]:
                print(f"    å‰3è¡Œå†…å®¹:")
                for i, line in enumerate(lines[:3], 1):
                    print(f"      è¡Œ{i}: {line.strip()[:60]}...")
        
        # åˆ é™¤æ£€æŸ¥ç‚¹æ–‡ä»¶
        if os.path.exists(CHECKPOINT_FILE):
            os.remove(CHECKPOINT_FILE)
            print("\nğŸ§¹ æ¸…ç†æ£€æŸ¥ç‚¹æ–‡ä»¶")
        
        await logger.write(f"\n{'='*60}\n")
        await logger.write("âœ… å¤„ç†å®Œæˆ!\n")
        await logger.write(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’\n")
        await logger.write(f"ğŸš€ å¹³å‡é€Ÿåº¦: {total_images/total_time:.2f} å¼ /ç§’\n")
        await logger.write(f"ğŸ“Š æˆåŠŸ: {total_successful} å¼  | å¤±è´¥: {total_failed} å¼ \n")
        await logger.write(f"ğŸ“ ä¿å­˜æ–‡ä»¶æ•°: {total_files} ä¸ª\n")
        await logger.write(f"ğŸ“ æ€»æè¿°è¡Œæ•°: {total_images * 5} è¡Œ\n")
        await logger.write(f"{'='*60}\n")
        
    except Exception as e:
        print(f"\nğŸ’¥ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc(file=logger.terminal)
        
        # å‘ç”Ÿå¼‚å¸¸æ—¶ä¿å­˜å½“å‰çŠ¶æ€
        try:
            checkpoint_data = {
                "processed_count": progress_tracker.processed if 'progress_tracker' in locals() else 0,
                "file_count": file_count if 'file_count' in locals() else 0,
                "failed_images": failed_images if 'failed_images' in locals() else [],
                "all_descriptions": all_descriptions if 'all_descriptions' in locals() else {},
                "current_file_number": current_file_number if 'current_file_number' in locals() else 1,
                "current_file_start_idx": current_file_start_idx if 'current_file_start_idx' in locals() else 0,
                "timestamp": time.time()
            }
            
            async with checkpoint_lock:
                await save_checkpoint(checkpoint_data)
            print("ğŸ’¾ å·²ä¿å­˜å¼‚å¸¸æ—¶çš„æ£€æŸ¥ç‚¹")
        except:
            pass
    finally:
        await asyncio.sleep(1)
        await logger.close()

# ==================== å…¥å£ ====================
if __name__ == "__main__":
    print("Flickr30kæµ‹è¯•é›†å¤„ç†ç¨‹åºå¯åŠ¨ï¼ˆå»é‡æ¨¡å¼ï¼‰...")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    print(f"è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    
    # æ£€æŸ¥æ˜¯å¦é‡å¤è¿è¡Œ
    if os.path.exists(PID_FILE):
        with open(PID_FILE, 'r') as f:
            old_pid = f.read().strip()
        try:
            os.kill(int(old_pid), 0)
            print(f"è­¦å‘Š: è¿›ç¨‹ {old_pid} å·²åœ¨è¿è¡Œ!")
            print(f"å¦‚éœ€é‡å¯ï¼Œè¯·åˆ é™¤: {PID_FILE}")
            sys.exit(1)
        except OSError:
            os.remove(PID_FILE)
    
    # ä¿å­˜PID
    with open(PID_FILE, 'w') as f:
        f.write(str(os.getpid()))
    print(f"PIDæ–‡ä»¶: {PID_FILE}")
    
    # è®¾ç½®ä¿¡å·å¤„ç†
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        print("å¼€å§‹å¼‚æ­¥ä¸»ç¨‹åº...")
        asyncio.run(main_async())
    except Exception as e:
        print(f"ä¸»ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if os.path.exists(PID_FILE):
            os.remove(PID_FILE)
        print("ç¨‹åºç»“æŸ")
